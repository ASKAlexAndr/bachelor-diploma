
\section{Искусственные нейронные сети}

\subsection{Понятие искусственной нейронной сети}

Машинное обучение (Machine Learning) – раздел исследований в сфере ИИ, в основе которых лежат методы разработки систем способных к обучению. Алгоритмы машинного обучения эффективно себя показывают в задачах, в которых требуется у заранее подготовленных (обучающих) данных определить общие признаки и по ним идентифицировать новые данные. В проектировании таких, обучающихся, систем часто применяют искуственные нейронные сети. 

Искусственная нейронная сеть (ИНС) – компьютерная модель, в основе которой лежат принципы работы биологической нейронной сети - совокупности связанных между собой нервных клеток - нейронов. Каждый нейрон имеет набор входных связей - синапсов, по которым он получает информацию, представленную в виде импульсов, от других нейронов. По полученным данным нейрон формирует своё состояние и, с помощью аксона, сообщает его другим нейронам, обеспечивая функционирование системы. В процессе формирования системы одни нейронные связи укрепляются, а другие ослабляются, обеспечивая обучаемость сети.
\addimghere{biological-neuron}{0.5}{Типичная структура биологического нейрона}{biological-neuron}

Искусственный нейрон представляет собой упрощенную модель биологического нейрона. Принцип его работы представлен на рисунке \ref{simple-neuron}. Сначала нейрон получает n-мерные вектор входных значений $X=(x_{1},...,x_{n})$ и вектор весов $W=(w_{1},...,w_{n})$, обозначающий <<укрепленность>> межнейронных связей. Вычесляется сумма произведения входных значений и весов $s_j$. Затем к полученному результату применяется \hyperref[sec:activation]{функция активации} ($\varphi$). В некоторых случаях, к сумме прибавляется величина смещения $b_j$.
\input{thesis/extra/neuron.tex}

Множества нейронов формируют слои, слои в свою очередь формируют нейронную сеть. Входной слой получает данные, обрабатывает и передает нейронам скрытого слоя. Аналогично срабатывет каждый последующий слой вплоть до выходного. 
\input{thesis/extra/neural-network.tex}

Нейросети с большим количеством скрытых слоев называется глубокими. Область машинного обучения, в которой используются глубокие нейронные сети называется - глубоким обучением (Deep Learning).     

\subsection{Активационная функция}
\label{sec:activation}
Взвешенная сумма входов представляет собой линейную комбинацию, из чего следует, что независимо от количества слоев, значения выходного слоя зависят только от входов первого слоя. 
Активационная функция нейрона обеспечивает нормализацию посчитанной суммы и нелинейность нейронной сети. Для многих моделей нейронных сетей также требуется, чтобы активационная функция была монотонной и непрерывно-дифференцируемой на всей области определения.

Существует большое количество функций активации. Наиболее распространенные из них представлены в табл. \ref{actvs}.

\input{thesis/extra/activation-functions.tex}

\subsection{Обучение нейронных сетей}
Под обучением нейронных сетей подразумевают настройку значений весов связей для эффективного решения поставленной задачи. Изначально, веса устанавливаются случайно. Затем, в процессе прогона через сеть тестовых данных, веса корректируются так, чтобы в конечном итоге сеть выдавала правильные ответы. 

Существует несколько подходов к обучению нейронных сетей:

\subparagraph{Обучение с учителем} \mbox{} \\
Обучение с учителем - это такой тип обучения, в котором сеть получает набор входных данных с заранее известными правильными ответами. Веса корректируются в зависимости от того, правильный ли ответ дала сеть. 

Одним из популярных методов обучения с учителем является алгоритм обратного распространения ошибки \cite{Nielsen2015}, который часто применяется в обучении глубоких нейронных сетей. 

Пусть сеть имеет L слоев, $a^l$, $w_{}^l$, $b^l$ - векторы значений, весов и смещений нейронов на $l$-м слое.. Также имеется N обучающих пар (x,y). 
В процессе обучения циклично происходят следующие итерации: 

\begin{enumerate}
    \item На вход сети подается вектор x из обучающего множества, для каждого слоя вычислить значения: \hfill $z^l = w^la^{l-1}+b^l и a^l = \sigma(z^l)$
    \item Вычислить значение функции стоимости: \hfill $C = \frac{1}{2}\sum_j{(y_j-a_j^L)^2}$
    \item Вычислить значения ошибок выходного слоя: \hfill $\delta_j^L=\frac{\delta C}{\delta a_j^L}\sigma'(z_j^L)$
    \item Вычислить ошибки для каждого предыдущего слоя: \hfill $\delta_j^l=\sum_k{w_{kj}^{l+1} \delta_k^{l+1}\sigma'(z_j^l)}$
    \item Вычислить градиент функции стоимости: \hfill $\frac{\delta C}{\delta w_{jk}^l} = a_k^{l-1} \delta_j^l$ % и $\frac{\delta C}{\delta b_j^l} = \delta_j^l$
    \item Обновить веса связей: \hfill $w_{ij}^l=w_{ij}^l-\mu\frac{\delta C}{\delta w_{jk}^l},\hspace{1em} 0<\mu \leqslant 1$
\end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% http://neuralnetworksanddeeplearning.com/chap2.html
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subparagraph{Обучение с подкреплением}\mbox{} \\
 Данный метод подразумевает наличие некоторой окружающей среды в которой действует сеть. Такая среда реагирует на действия модели и подает ей определенные сигналы.  

\subparagraph{Обучение без учителя}\mbox{} \\
Обучение при котором сеть заренее не располагает правильными ответами и самостоятельно ищет общие и отличительные признаки у входных данных. 


\subparagraph{Генетические алгоритмы обучения}\mbox{} \\
 Алгоритмы, имитирующие эволюционные механизмы развития биологической популяции, выступают как альтернатива алгоритму обратного распространения ошибки. Значение произвольного весового коэффициента в нейронной сети называется геном. Гены формируют хромосомы, а хромосомы - популяцию. Дальше, в пределах одного цикла (эпохи) с определенными вероятностями происходит: 
 \begin{itemize}
     \item Cкрещивание хромосом - формирование новой хромосомы из генов двух других
     \item мутация - случайное изменение произвольного гена
     \item приспособление - (хромосомы показавшие худшие результаты уничтожаются из популяции.
 \end{itemize}

+/- ???

\subsection{Сверточные нейронные сети}
Стандартные нейронные сети состоят из полносвязных слоев - слоев, в которых каждый нейрон связан с каждым нейроном следующего слоя, что значительно увеличивает вычислительную сложность системы при увеличении количества нейронов. 
В типовых сверточных нейронных сетях к полносвязным добавляются сверточные и подвыборочные слои. 

Сверточные слои характеризуются использованием матриц весов, называемых фильтрами или ядрами, которые обладают размерностью меньше исходных данных. Такое ядро с определенным шагом проходит по набору входных данных $(I)$ и вычисляет суммы произведений соответствующих значений ячеек и весов, формируя карту признаков $(I * K)$. Один сверточный слой может содержать несколько ядер и соответственно несколько карт признаков.

\input{thesis/extra/convolution}

Так как признаки уже обнаружены, для упрощения дальнейших вычислений можно снизить детализацию входных данных. Это обеспечивает подвыборочный (пулинговый) слой, сжимая карты признаков, полученные от сверточного слоя, что снижает количество параметров, используемых в дальнейших вычислениях сети. 

СНС может иметь несколько пар чередующихся сверточных и подвыборочных слоев. Завершается СНС стандартными полносвязными слоями.  

\subsection{Рекуррентные нейронные сети}
Все вышеуказанные архитектуры нейронных сетей являются статическими - имеют заранее заданные параметры, без возможности их корректирования в процессе работы сети.

\subsection{Инструменты машинного обучения}

TensorFlow - многофункциональный фреймворк для машинного обучения с открытым исходным кодом

???
\clearpage