\section{Сверточные нейронные сети} \label{CNN}

\subsection{Архитектура}

Большая часть современных нейронных сетей направленных на анализ изображений базируются на архитектуре сверточной нейронной сети.
Ранние нейронные сети состояли из полносвязных слоев - слоев, в которых каждый нейрон связан с каждым нейроном следующего слоя, что значительно увеличивало вычислительную сложность системы при увеличении количества нейронов. 
В типовых сверточных нейронных сетях преимущественно используются сверточные слои. 

Сверточные слои характеризуются использованием матриц весов, называемых фильтрами или ядрами, которые обладают размерностью меньше исходных данных. Такое ядро с определенным шагом проходит по набору входных данных $(I)$ и вычисляет суммы произведений соответствующих значений ячеек и весов, формируя карту признаков $(I * K)$. Один сверточный слой может содержать несколько ядер и соответственно несколько карт признаков.

\input{thesis/extra/convolution}

Так как признаки уже обнаружены, для упрощения дальнейших вычислений можно снизить детализацию входных данных. Это обеспечивает субдискретизирующий (пулинговый) слой, уменьшая размерность входных карт признаков: из нескольких соседних нейронов берется максимальное или среднее значение, тем самым формируя нейрон карты признаков меньшей размерности. Это позволяет снизить количество параметров, используемых в дальнейших вычислениях сети. 

\input{thesis/extra/pooling}

Сверточная нейронная сеть может иметь несколько пар чередующихся сверточных и субдискретизирующих слоев. 
Таким образом, на примере изображений, на начальных слоях сеть находит такие простейшие признаки как границы и углы. Затем, по мере углубления в сеть, определяются всё более сложные конструкции: от простейших фигур до целых классов, независимо от их местоположения на изображении. Завершается сеть стандартными полносвязными слоями которые сопоставляют полученные карты признаков какому-либо классу.  

\subsection{VGG}
Архитектура VGG была предложена в 2014 году\cite{simonyan2014convolutional}. Главной особенностью сети стало использование подряд стоящих сверточных слоев с фильтрами размерности 3x3 вместо применяемых ранее сверточных слоев с фильтрами большого размера 5x5, 7x7, 11x11. Это позволило снизить количество параметров сети с сохранением эффективности.

В таблице \ref{vgg} указаны различные конфигурации VGG, наиболее известные из них VGG-16 (D) и VGG-19 (E), названные по количеству слоев, содержащих веса. Maxpool - субдискретизирующий слой с функцией максимума размера 2x2. FC - полносвязный слой. Во всех скрытых слоях используется активационная функция ReLU. 

\input{thesis/extra/VGG.tex}

\subsection{Inception}
Данная модель\cite{1512.00567}, разработанная компанией Google, в 2014 году заняла 1 место в ежегодном конкурсе по классификации изображений - ILSVRC. Ключевым нововведением данной сети стало использование в качестве слоев вложенных модулей, которые представляют из себя набор фильтров разных размерностей, с последующим объединением их результатов. 

\input{thesis/extra/inception-module.tex}

Также, в Inception полностью отказались от использования полносвязных слоев, вместо них применяется глобальный средний пулинг, который преобразует каждую карту признаков к одному числу, формируя вектор усредненных значений. Такое нововведение позволило значительно уменьшить количество параметров и как следствие вычислительную сложность сети. В последствии были разработаны улучшенные версии Inception, в которых заменили слой 5x5 двумя последовательными слоями 3x3, а также все слои c фильтрами размера NxN заменили на стек фильтров 1xN и Nx1, что также позволило снизить количество параметров.

\subsection{ResNet}
ResNet\cite{ResNet}, также известная как остаточная нейронная сеть, выиграла ILSVRC в 2015 году. Её особенностью было наличие пропускающих соединений, которые передают информацию без изменений на более глубокие участки сети, эта информация суммируется с вычисленным на пропущенных слоях значением и передается дальше. Блок изображенный на рис. \ref{res-net} демонстрирует составной элемент такой сети.

\input{thesis/extra/ResNet.tex}

\subsection{DenseNet}
DenseNet\cite{DenseNet} - плотная сверточная сеть, похожая на ResNet, но с той разницей, что все блоки сети соединены прямыми связями между собой, таким образом каждый блок получает информацию от всех предыдущих. 

\input{thesis/extra/denseNets.tex}

% \subsection{Xception}

\subsection{Тестирование}
Все указанные модели тестировались на наборах данных ImageNet, который включает в себя 1000 классов, свыше 1.3 млн. тренировочных и 50 тыс. проверочных изображений. Так как сети выполняют задачу классификации и используют на конце Softmax-слой, результатом сети является вектор $(x_1,x_2,...x_n)$, где n - количество классов, а $x_i$ - вероятность отношения входного изображения к i-му классу. Toчность сетей измерялась в двух вариантах Top-1 и Top-5. Top-1 означает, что наибольшее $x_i$ соответствует правильному классу, а Top-5 - что правильный класс принадлежит пяти самых высоким значениям в выходном векторе сети. В таблице \ref{conv-test} указаны результаты проведенных проверок по метрике accuracy - отношение доли правильных ответов к общему их количеству. 

\input{thesis/extra/conv-test.tex}

Как можно видеть на таблице: сети VGG имеют самое большое количество параметров, значительно превосходя другие модели, при этом демонстрируют самую низкую точность. Сети DenseNet показывают лучшее соотношение точности и количества параметров. Однако третья версия Inception имеет относительно немного больше параметров и точность. Лучший результат показала ResNet-152 второй версии, но она обладает значительно большим количеством параметров, что сказывается на времени обучения сети.

\clearpage