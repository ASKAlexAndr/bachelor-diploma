\section{Машинное обучение}

\subsection{Понятие искусственной нейронной сети}

Машинное обучение – раздел исследований в сфере ИИ, в основе которых лежат методы разработки систем способных к обучению. Алгоритмы машинного обучения эффективно себя показывают в задачах, в которых требуется у заранее подготовленных (обучающих) данных определить общие признаки и по ним идентифицировать новые данные. В проектировании таких, обучающихся, систем часто применяют искуственные нейронные сети. 

Искусственная нейронная сеть (ИНС) – компьютерная модель, в основе которой лежат принципы работы биологической нейронной сети - совокупности связанных между собой нервных клеток - нейронов. Каждый нейрон имеет набор входных связей - синапсов, по которым он получает информацию, представленную в виде импульсов, от других нейронов. По полученным данным нейрон формирует своё состояние и, с помощью аксона, сообщает его другим нейронам, обеспечивая функционирование системы. В процессе формирования системы одни нейронные связи укрепляются, а другие ослабляются, обеспечивая обучаемость сети.
\addimghere{biological-neuron}{0.5}{Типичная структура биологического нейрона}{biological-neuron}

Искусственный нейрон представляет собой упрощенную модель биологического нейрона. Принцип его работы представлен на рисунке \ref{simple-neuron}. Сначала нейрон получает n-мерные вектор входных значений $X=(x_{1},...,x_{n})$ и вектор весов $W=(w_{1},...,w_{n})$, обозначающий <<укрепленность>> межнейронных связей. Вычесляется сумма произведения входных значений и весов $s_j$. Затем к полученному результату применяется \hyperref[sec:activation]{функция активации} $\varphi$. В некоторых случаях, к сумме прибавляется величина смещения $b_j$.
\input{thesis/extra/neuron.tex}

Множества нейронов формируют слои, слои в свою очередь формируют нейронную сеть. Входной слой получает данные, обрабатывает и передает нейронам скрытого слоя. Аналогично срабатывет каждый последующий слой вплоть до выходного. 
\input{thesis/extra/neural-network.tex}

Нейросети с большим количеством скрытых слоев называется глубокими. Область машинного обучения, в которой используются глубокие нейронные сети называется - глубоким обучением.     

\subsection{Активационная функция}
\label{sec:activation}
Взвешенная сумма входов представляет собой линейную комбинацию, из чего следует, что независимо от количества слоев, значения выходного слоя зависят только от входов первого слоя. 
Активационная функция нейрона обеспечивает нормализацию посчитанной суммы и нелинейность нейронной сети. Для многих моделей нейронных сетей также требуется, чтобы активационная функция была монотонной и непрерывно-дифференцируемой на всей области определения.

Существует большое количество функций активации. Наиболее распространенные из них представлены в таблице \ref{actvs}.

\input{thesis/extra/activation-functions.tex}

Отдельно стоит упоминуть функцию Softmax. Эта функция часто применяется на последнем слое глубоких нейронных сетей в задачах классификации. Пусть последний слой сети содержит N нейронов, каждый из которых соответствует некоторому классу. Тогда значение выхода i-го нейрона вычисляется по формуле: 
\[
    y_i=\frac{e^{z_i}}{\sum\limits_{j=1}^{N}e^{z_j}}
\]
Таким образом, результат каждого нейрона будет принимать значения из диапазона $[0,1]$, а их сумма равна 1. Тем самым сеть выдаст вероятности отношения входных данных к заданным классам.

\subsection{Обучение нейронных сетей}
Под обучением нейронных сетей подразумевается подбор значений весов связей для эффективного решения поставленной задачи. Изначально, веса устанавливаются случайно. Затем, в процессе прогона через сеть тестовых данных, веса корректируются так, чтобы в конечном итоге сеть выдавала правильные ответы. 

% Для более эффективной работы нейронной сети 
Существует несколько подходов к обучению нейронных сетей:

\textbf{Обучение с учителем} - наиболее распространенный тип обучения, в котором сеть получает набор входных данных с заранее известными правильными ответами. Веса корректируются в зависимости от того, правильный ли ответ дала сеть. 

\textbf{Обучение с подкреплением} - метод, который подразумевает наличие некоторой окружающей среды в которой действует сеть. Такая среда реагирует на действия модели и подает ей определенные сигналы.  

\textbf{Обучение без учителя} - обучение при котором сеть заренее не располагает правильными ответами и самостоятельно ищет общие и отличительные признаки у входных данных. 

\textbf{Генетические алгоритмы обучения} - алгоритмы, имитирующие эволюционные механизмы развития биологической популяции, выступают как альтернатива алгоритму обратного распространения ошибки. Значение произвольного весового коэффициента в нейронной сети называется геном. Гены формируют хромосомы, а хромосомы - популяцию. Дальше, в пределах одного цикла (эпохи) с определенными вероятностями происходит: 
 \begin{itemize}
     \item Cкрещивание хромосом - формирование новой хромосомы из генов двух других
     \item мутация - случайное изменение произвольного гена
     \item приспособление - (хромосомы показавшие худшие результаты уничтожаются из популяции.
 \end{itemize}

\subsection{Функция потерь}
 Для того, чтобы контролировать процесс обучения необходимо как-то оценивать работу сети. Для этого вводится функия потерь (функция стоимости), которая вычисляет разницу между правильными и полученными результатами и формирует некоторое численное значение, характеризующее величину ошибки работы сети. Таким образом задача обучения сети сводится к задаче минимизации данной функции. В таблице \ref{loss_funcs} указаны наиболее часто используемые функции потерь, где $y_i$ – ожидаемое значение i-го нейрона, $x_i$ – полученное значение i-го нейрона, n – количество выходных нейронов.

 \input{thesis/extra/loss-functions.tex}
% \subsection{Рекуррентные нейронные сети}
% Одним из минусов указанных выше моделей является их неспособность анализировать наборы данных, в которых важен порядок, например при работе с текстом или видеорядом. Эту проблему решают рекуррентные нейронные сети, особенностью которых является наличие обратных связей, которые позволяют передавать информацию на следующий шаг системы.
% \input{thesis/extra/RNN.tex}

\subsection{Проблемы обучения глубоких нейронных сетей}

% Одним из популярных методов в обучении глубоких нейронных сетей является алгоритм обратного распространения ошибки, основанный на градиентном спуске. 

% Пусть сеть имеет L слоев, $a^l$, $w_{}^l$, $b^l$ - векторы значений, весов и смещений нейронов на $l$-м слое.. Также имеется N обучающих пар (x,y). 
% В процессе обучения циклично происходят следующие итерации: 

% \begin{enumerate}
%     \item На вход сети подается вектор x из обучающего множества, для каждого слоя вычислить значения: \hfill $z^l = w^la^{l-1}+b^l и a^l = \sigma(z^l)$
%     \item Вычислить значение функции стоимости: \hfill $C = \frac{1}{2}\sum_j{(y_j-a_j^L)^2}$
%     \item Вычислить значения ошибок выходного слоя: \hfill $\delta_j^L=\frac{\delta C}{\delta a_j^L}\sigma'(z_j^L)$
%     \item Вычислить ошибки для каждого предыдущего слоя: \hfill $\delta_j^l=\sum_k{w_{kj}^{l+1} \delta_k^{l+1}\sigma'(z_j^l)}$
%     \item Вычислить градиент функции стоимости: \hfill $\frac{\delta C}{\delta w_{jk}^l} = a_k^{l-1} \delta_j^l$ % и $\frac{\delta C}{\delta b_j^l} = \delta_j^l$
%     \item Обновить веса связей: \hfill $w_{ij}^l=w_{ij}^l-\mu\frac{\delta C}{\delta w_{jk}^l},\hspace{1em} 0<\mu \leqslant 1$
% \end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% http://neuralnetworksanddeeplearning.com/chap2.html
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Не смотря на то, что данный алгоритм и его вариации успешно показали себя в задачах обучения глубоких сетей, у него имеется ряд недостатков. При обратном ходе, значения градиентов экспоненциально быстро уменьшается, как следствие веса у более ранних слоев корректируются слабо. Такая трудность называется проблемой "исчезающего" градиента. 

Переобучение сети - проблема, заключающаяся в том, что сеть хорошо анализирует объекты из обучающей выборки, но плохо работает с новыми данными. Одним из методов решения этой проблемы является Dropout, суть которого заключается в выключении случайных нейронов в сети на каждом этапе обучения.

 \input{thesis/extra/dropout.tex}


\clearpage